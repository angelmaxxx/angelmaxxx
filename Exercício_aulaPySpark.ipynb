{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelmaxxx/angelmaxxx/blob/main/Exerc%C3%ADcio_aulaPySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wF9sOF_Tvar"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "zS1IE-GETyqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Para deixar a visualição das tabelas mais amigável\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "28fV3Q7gT1Ia",
        "outputId": "404ecc86-ac02-49d8-a7dd-bd4d2dc3e56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7902b4753a30>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5ed35497b78d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 1:\n",
        "Em ambiente PySpark crie uma tabela com quatro atributos sendo o\n",
        "primeiro qualitativo e os demais como quantitivos e dez registros\n",
        "(linhas para a tabela) sem registros nulos.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 2:\n",
        "Em ambiente PySpark gerar um describe da tabela gerada no requisito anterior e recebê-lo\n",
        "com um df pyspark.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 3:\n",
        "Em ambiente PySpark Selecionar a linha de desvio padrão do df gerar uma lista\n",
        "no ambiente python e armazená-lo com o nome sd\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 4:\n",
        "Em ambiente Python, manipular essa lista e a partir dela gerar uma lista\n",
        "com todos os valores numéricos da lista sd elevado ao quadrado e receber essa\n",
        "nova lista com o nome var\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 5:\n",
        "Transformar cada lista do requisito anterior em um df py spark\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 6:\n",
        "Em ambiente Pyspark juntar os dois dfs criados no requisito anterior e\n",
        "armazená-lo em um df pyspark chamado sd_var\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 7:\n",
        "Em ambiente Pyspark gerar uma junção do df da variância com o df das medidas\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 8:\n",
        "criar uma lista que contenha as modas de todos os atributos quantitativos\n",
        "do df inicial e inseri-la no df pyskar de mesdidas\n",
        "'''\n",
        "'''\n",
        "Requisito 9:\n",
        "Em ambiente Pyspark e Python e de forma semelahnte ao que foi feito nos\n",
        "requisitos anteriores\n",
        "\n",
        "Calcule e adicione ao df de medidas do pyspark as seguintes linhas com seus\n",
        "respectivos valores para as medidas:\n",
        "* Mediana\n",
        "* Q1\n",
        "* Q3\n",
        "* AT\n",
        "* AIQ\n",
        "* LS\n",
        "* LI\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "MKayJLwcUGr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 1:\n",
        "Em ambiente PySpark crie uma tabela com quatro atributos sendo o\n",
        "primeiro qualitativo e os demais como quantitivos e dez registros\n",
        "(linhas para a tabela) sem registros nulos.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Criação do schema que nada mais é do que o esqueleto da tabela\n",
        "'''\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DoubleType # importando estrutura da tabela (structType)\n",
        "schema = StructType([ \\\n",
        "    StructField('nome',StringType(),True), \\\n",
        "    StructField('idade',IntegerType(),True), \\\n",
        "    StructField('altura',DoubleType(),True), \\\n",
        "    StructField('peso', DoubleType(), True), \\\n",
        "  ])\n",
        "\n",
        "'''\n",
        "Criação do objeto (nível Python) que contém as tuplas com os regitros que farão\n",
        "parte da tabela\n",
        "'''\n",
        "dados = [('Douglas',45,1.85,70.),\n",
        "    ('Daniela',7,1.23,22.),\n",
        "    ('Pedro',65,1.75,87.),\n",
        "    ('Maria',64,1.67,64.),\n",
        "    ('Eduardo',37,1.82,96.),\n",
        "    ('Ester',37,1.73,69.),\n",
        "    ('Tobias',18,1.82,96.),\n",
        "    ('Angela',32,1.72,70.),\n",
        "    ('Dagmar',35,1.65,63.),\n",
        "    ('Everaldo',37,1.82,96.)\n",
        "  ]\n",
        "'''\n",
        "Criação do dataframe py spark juntando a estutura da tabela com o objeto\n",
        "que contém os registros\n",
        "'''\n",
        "df_py = spark.createDataFrame(data=dados,schema=schema)\n",
        "'''\n",
        "Imprimir o schema do df_py\n",
        "'''\n",
        "df_py.printSchema()\n",
        "\n",
        "'''\n",
        "Mostrar o df_py\n",
        "'''\n",
        "df_py.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkFZ6gG5UKUY",
        "outputId": "991e116b-b1c2-4ca2-debd-1a071207d0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nome: string (nullable = true)\n",
            " |-- idade: integer (nullable = true)\n",
            " |-- altura: double (nullable = true)\n",
            " |-- peso: double (nullable = true)\n",
            "\n",
            "+--------+-----+------+----+\n",
            "|    nome|idade|altura|peso|\n",
            "+--------+-----+------+----+\n",
            "| Douglas|   45|  1.85|70.0|\n",
            "| Daniela|    7|  1.23|22.0|\n",
            "|   Pedro|   65|  1.75|87.0|\n",
            "|   Maria|   64|  1.67|64.0|\n",
            "| Eduardo|   37|  1.82|96.0|\n",
            "|   Ester|   37|  1.73|69.0|\n",
            "|  Tobias|   18|  1.82|96.0|\n",
            "|  Angela|   32|  1.72|70.0|\n",
            "|  Dagmar|   35|  1.65|63.0|\n",
            "|Everaldo|   37|  1.82|96.0|\n",
            "+--------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 2:\n",
        "Em ambiente PySpark gerar um describe da tabela gerada no requisito anterior e\n",
        "recebê-lo com um df pyspark.\n",
        "'''\n",
        "medidas = df_py.describe()\n",
        "medidas.show()\n",
        "medidas = medidas.drop(\"nome\")\n",
        "medidas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwHyBQZcUNJ8",
        "outputId": "c7b5da64-fcf4-460e-e2ad-fb368b48ffdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-------------------+------------------+\n",
            "|summary|  nome|             idade|             altura|              peso|\n",
            "+-------+------+------------------+-------------------+------------------+\n",
            "|  count|    10|                10|                 10|                10|\n",
            "|   mean|  null|              37.7| 1.7060000000000002|              73.3|\n",
            "| stddev|  null|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|    min|Angela|                 7|               1.23|              22.0|\n",
            "|    max|Tobias|                65|               1.85|              96.0|\n",
            "+-------+------+------------------+-------------------+------------------+\n",
            "\n",
            "+-------+------------------+-------------------+------------------+\n",
            "|summary|             idade|             altura|              peso|\n",
            "+-------+------------------+-------------------+------------------+\n",
            "|  count|                10|                 10|                10|\n",
            "|   mean|              37.7| 1.7060000000000002|              73.3|\n",
            "| stddev|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|    min|                 7|               1.23|              22.0|\n",
            "|    max|                65|               1.85|              96.0|\n",
            "+-------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 3:\n",
        "Em ambiente PySpark Selecionar a linha de desvio padrão do df gerar uma lista\n",
        "no ambiente python e armazená-lo com o nome sd\n",
        "'''\n",
        "sd = list(medidas.collect()[2])\n",
        "print(sd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOrPR9kYUPoD",
        "outputId": "307aa0ca-41fa-4bfa-b175-b56765e1585d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stddev', '17.832866037491314', '0.18056700818378885', '22.603097132915217']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 4:\n",
        "Em ambiente Python, manipular essa lista e a partir dela gerar uma lista\n",
        "com todos os valores numéricos da lista sd elevado ao quadrado e receber essa\n",
        "nova lista com o nome var\n",
        "'''\n",
        "sd.pop(0)\n",
        "print(sd)\n",
        "var = []\n",
        "for i in range(len(sd)):\n",
        "  sd[i] = float(sd[i])\n",
        "  var.append(sd[i]**2)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrsNpKPddKYM",
        "outputId": "d9078660-e298-47f9-9002-363743034efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['17.832866037491314', '0.18056700818378885', '22.603097132915217']\n",
            "[318.0111111111112, 0.03260444444444447, 510.9000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 5:\n",
        "Transformar cada lista do requisito anterior em um df py spark\n",
        "'''\n",
        "sd.insert(0,'desvio padrão')\n",
        "var.insert(0, 'variância')\n",
        "#sd = tuple(sd)\n",
        "#var = tuple(var)\n",
        "df_var = spark.createDataFrame([var])\n",
        "df_sd = spark.createDataFrame([sd],[\"summary\",\"idade\",\"altura\",\"peso\"])\n",
        "df_sd.show()\n",
        "df_var.show()\n",
        "df_var.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFc8vwjLkSPV",
        "outputId": "ecbbe58d-6af5-431a-db30-d156b975594a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+-------------------+------------------+\n",
            "|      summary|             idade|             altura|              peso|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "|desvio padrão|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "\n",
            "+---------+-----------------+-------------------+-----------------+\n",
            "|       _1|               _2|                 _3|               _4|\n",
            "+---------+-----------------+-------------------+-----------------+\n",
            "|variância|318.0111111111112|0.03260444444444447|510.9000000000001|\n",
            "+---------+-----------------+-------------------+-----------------+\n",
            "\n",
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: double (nullable = true)\n",
            " |-- _3: double (nullable = true)\n",
            " |-- _4: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 6:\n",
        "Em ambiente Pyspark juntar os dois dfs criados no requisito anterior e\n",
        "armazená-lo em um df pyspark chamado sd_var\n",
        "'''\n",
        "\n",
        "df_sd_var = df_sd.union(df_var)\n",
        "df_sd_var.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW66OlGIrd5F",
        "outputId": "72cca532-b764-4924-a82b-860d6c573fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+-------------------+------------------+\n",
            "|      summary|             idade|             altura|              peso|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "|desvio padrão|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|    variância| 318.0111111111112|0.03260444444444447| 510.9000000000001|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 7:\n",
        "Em ambiente Pyspark fazer a inclusão do df da variância no df das medidas\n",
        "'''\n",
        "medidas = medidas.union(df_var)\n",
        "medidas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8AOSWbWsrJq",
        "outputId": "6ca54138-a0ca-46d3-c706-cc090f3f3ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+-------------------+------------------+\n",
            "|  summary|             idade|             altura|              peso|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "|    count|                10|                 10|                10|\n",
            "|     mean|              37.7| 1.7060000000000002|              73.3|\n",
            "|   stddev|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|      min|                 7|               1.23|              22.0|\n",
            "|      max|                65|               1.85|              96.0|\n",
            "|variância| 318.0111111111112|0.03260444444444447| 510.9000000000001|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 8:\n",
        "criar uma lista que contenha as modas de todos os atributos quantitativos\n",
        "do df inicial e inserí-la no df pyskark de medidas\n",
        "'''\n",
        "[df_py.groupby(i).count().orderBy(\"count\", ascending=False).first()[0] for i in df_py.columns]\n",
        "'''\n",
        "agrupando no df original os valores das colunas e contando os valores e ordenando\n",
        "esses valores de forma descrescente (da maior contagem para a menor) e selecionando\n",
        "o primeiro da linha 0 e tudo para cada valor de cada coluna do df original\n",
        "'''\n",
        "moda = [df_py.groupby(i).count().orderBy(\"count\", ascending=False).first()[0] for i in df_py.columns]\n",
        "moda.pop(0)\n",
        "moda.insert(0,'moda')\n",
        "moda = spark.createDataFrame([moda])\n",
        "medidas = medidas.union(moda)"
      ],
      "metadata": {
        "id": "8NO_U2YWuYQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medidas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRniqf_vLVJ8",
        "outputId": "6dbc2bb0-3b22-4037-d635-c3703f2e8806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+-------------------+------------------+\n",
            "|  summary|             idade|             altura|              peso|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "|    count|                10|                 10|                10|\n",
            "|     mean|              37.7| 1.7060000000000002|              73.3|\n",
            "|   stddev|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|      min|                 7|               1.23|              22.0|\n",
            "|      max|                65|               1.85|              96.0|\n",
            "|variância| 318.0111111111112|0.03260444444444447| 510.9000000000001|\n",
            "|     moda|                37|               1.82|              96.0|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 9:\n",
        "Em ambiente Pyspark e Python e de forma semelahnte ao que foi feito nos\n",
        "requisitos anteriores\n",
        "\n",
        "Calcule e adicione ao df de medidas do pyspark as seguintes linhas com seus\n",
        "respectivos valores para as medidas:\n",
        "* Mediana\n",
        "* Q1\n",
        "* Q3\n",
        "* AT\n",
        "* AIQ\n",
        "* LS\n",
        "* LI\n",
        "\n",
        "'''\n",
        "\n",
        "df_py.approxQuantile(['idade','altura','peso'], [0.25,0.5,0.75], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq4NQ_gVkZIv",
        "outputId": "12770579-28e5-4779-ba9c-a65ecd884fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32.0, 37.0, 45.0], [1.67, 1.73, 1.82], [64.0, 70.0, 96.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quartis = df_py.approxQuantile(['idade','altura','peso'], [0.25,0.5,0.75], 0)\n",
        "print(quartis)\n",
        "q1 = [quartis[0][0], quartis[1][0], quartis[2][0]]\n",
        "print(q1)\n",
        "med = [quartis[0][1], quartis[1][1], quartis[2][1]]\n",
        "print(med)\n",
        "q3 = [quartis[0][2], quartis[1][2], quartis[2][2]]\n",
        "print(q3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLfhWIGTt-dP",
        "outputId": "a9cdbc84-9dea-493d-bc43-bf05bcea6efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32.0, 37.0, 45.0], [1.67, 1.73, 1.82], [64.0, 70.0, 96.0]]\n",
            "[32.0, 1.67, 64.0]\n",
            "[37.0, 1.73, 70.0]\n",
            "[45.0, 1.82, 96.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min = medidas.collect()[3]"
      ],
      "metadata": {
        "id": "HhMTiJEBxjEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8kv5ueU0t95",
        "outputId": "a33c5a30-79e4-4b81-a0c6-361860cc981a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(summary='min', idade='7', altura='1.23', peso='22.0')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float(min['peso'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVllIaC217Jn",
        "outputId": "787e8637-1b75-43bf-b557-398aa195dc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.0"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minimo = [float(min['idade']),float(min['altura']),float(min['peso'])]\n",
        "print(minimo)\n",
        "\n",
        "max = medidas.collect()[4]\n",
        "maximo = [float(max['idade']),float(max['altura']),float(max['peso'])]\n",
        "print(maximo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxwf0cVb03zo",
        "outputId": "43d282e1-eb53-4e0f-fc1b-e786d0b1e076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.0, 1.23, 22.0]\n",
            "[65.0, 1.85, 96.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "at = [] # Criando a lista que receberá os valores de amplitude total\n",
        "aiq = [] # Criando a lista que receberá os valores de amplitude interquartílica\n",
        "li = [] # Criando a lista que receberá os valores de limite inferior do BoxPlot\n",
        "ls = [] # Criando a lista que receberá os valores de limite superior do BoxPlot\n",
        "for i in range(len(minimo)): # criando o for para fazer os cálculos\n",
        "  at.append(maximo[i]-minimo[i])# calculando e apendando os valores de amplitude\n",
        "  aiq.append(q3[i]-q1[i])# calculando e apendando os valores de amplitude interquartílica\n",
        "  li.append(q1[i]-1.5*aiq[i]) # calculando e apendando os valores de limite inferior\n",
        "  ls.append(q3[i]+1.5*aiq[i]) # calculando e apendando os valores de limite superior\n",
        "q1.insert(0, 'Q1')\n",
        "med.insert(0, 'mediana')\n",
        "q3.insert(0, 'Q3')\n",
        "at.insert(0, 'AT')\n",
        "aiq.insert(0, 'AIQ')\n",
        "li.insert(0, 'LI')\n",
        "ls.insert(0, 'LS')\n",
        "print(q1)\n",
        "print(med)\n",
        "print(q3)\n",
        "print(at)\n",
        "print(aiq)\n",
        "print(li)\n",
        "print(ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTJHz24o4M3p",
        "outputId": "04852b44-d660-4fb9-ca45-dfc092818b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Q1', 32.0, 1.67, 64.0]\n",
            "['mediana', 37.0, 1.73, 70.0]\n",
            "['Q3', 45.0, 1.82, 96.0]\n",
            "['AT', 58.0, 0.6200000000000001, 74.0]\n",
            "['AIQ', 13.0, 0.15000000000000013, 32.0]\n",
            "['LI', 12.5, 1.4449999999999998, 16.0]\n",
            "['LS', 64.5, 2.0450000000000004, 144.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adc = spark.createDataFrame([q1,med,q3,at,aiq,li,ls])\n",
        "adc.show()"
      ],
      "metadata": {
        "id": "Hs0oimGz_mWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medidas = medidas.union(adc)\n",
        "medidas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv23VJtvAhLq",
        "outputId": "58fd1fdb-11af-4b9f-934e-cad72b6ae75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+-------------------+------------------+\n",
            "|  summary|             idade|             altura|              peso|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "|    count|                10|                 10|                10|\n",
            "|     mean|              37.7| 1.7060000000000002|              73.3|\n",
            "|   stddev|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|      min|                 7|               1.23|              22.0|\n",
            "|      max|                65|               1.85|              96.0|\n",
            "|variância| 318.0111111111112|0.03260444444444447| 510.9000000000001|\n",
            "|     moda|                37|               1.82|              96.0|\n",
            "|       Q1|              32.0|               1.67|              64.0|\n",
            "|  mediana|              37.0|               1.73|              70.0|\n",
            "|       Q3|              45.0|               1.82|              96.0|\n",
            "|       AT|              58.0| 0.6200000000000001|              74.0|\n",
            "|      AIQ|              13.0|0.15000000000000013|              32.0|\n",
            "|       LI|              12.5| 1.4449999999999998|              16.0|\n",
            "|       LS|              64.5| 2.0450000000000004|             144.0|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Contribuição cedida gentilmente pelo aluno Diego, com a colaboração dos alunos\n",
        "Aska, Gus e Samira\n",
        "'''\n",
        "from pyspark.sql.functions import col\n",
        "#Lista todas as Colunas do dataframe\n",
        "todas_colunas = [coluna for coluna, tipo in df_py.dtypes ]\n",
        "#Lista todas as Colunas do dataframe\n",
        "colunas_numericas = [coluna for coluna, tipo in df_py.dtypes if tipo in ['double', 'float', 'decimal', 'int', 'long']]\n",
        "# Calculando os quartis de todos os atributos quantitativos\n",
        "quartis = df_py.approxQuantile(colunas_numericas, [0.25,0.5,0.75], 0)\n",
        "quartis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuSO-ZYdCFIF",
        "outputId": "1f522a97-ec70-41c1-be54-a20b61247829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32.0, 37.0, 45.0], [1.67, 1.73, 1.82], [64.0, 70.0, 96.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_py.printSchema()\n",
        "df_py.dtypes\n",
        "#Conferir se o tipo do schema é o mesmo do df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ_UbAyjGQqu",
        "outputId": "cf1c8dd3-fd8b-47cf-cb48-27eb32725057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nome: string (nullable = true)\n",
            " |-- idade: integer (nullable = true)\n",
            " |-- altura: double (nullable = true)\n",
            " |-- peso: double (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nome', 'string'),\n",
              " ('idade', 'int'),\n",
              " ('altura', 'double'),\n",
              " ('peso', 'double')]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
        "\n",
        "# Número de linhas\n",
        "num_linhas = df_py.count()\n",
        "print(\"Número de linhas: \", num_linhas)\n",
        "\n",
        "# Número de colunas\n",
        "num_colunas = len(df_py.columns)\n",
        "print(\"Número de colunas: \", num_colunas)\n",
        "\n",
        "# Nomes das colunas e seus tipos\n",
        "print(\"Esquema do DataFrame:\")\n",
        "df_py.printSchema()\n",
        "\n",
        "# Contagem de valores não nulos por coluna\n",
        "print(\"Contagem de valores não nulos por coluna:\")\n",
        "df_py.agg(*[(count(when(col(c).isNotNull(), c)).alias(c)) for c in df_py.columns]).show()\n",
        "\n",
        "# Contagem de valores nulos por coluna\n",
        "print(\"Contagem de valores nulos por coluna:\")\n",
        "df_py.agg(*[(count(when(isnull(col(c)), c)).alias(c)) for c in df_py.columns]).show()\n",
        "\n",
        "# Contagem de valores ausentes por coluna\n",
        "print(\"Contagem de valores ausentes por coluna:\")\n",
        "df_py.agg(*[(count(when(isnan(col(c)) | isnull(col(c)), c)).alias(c)) for c in df_py.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZdaYnmbD4OZ",
        "outputId": "eb11f4cd-27f4-4adc-d2e7-32ba75689000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de linhas:  10\n",
            "Número de colunas:  4\n",
            "Esquema do DataFrame:\n",
            "root\n",
            " |-- nome: string (nullable = true)\n",
            " |-- idade: double (nullable = true)\n",
            " |-- altura: double (nullable = true)\n",
            " |-- peso: double (nullable = true)\n",
            "\n",
            "Contagem de valores não nulos por coluna:\n",
            "+----+-----+------+----+\n",
            "|nome|idade|altura|peso|\n",
            "+----+-----+------+----+\n",
            "|  10|   10|    10|  10|\n",
            "+----+-----+------+----+\n",
            "\n",
            "Contagem de valores nulos por coluna:\n",
            "+----+-----+------+----+\n",
            "|nome|idade|altura|peso|\n",
            "+----+-----+------+----+\n",
            "|   0|    0|     0|   0|\n",
            "+----+-----+------+----+\n",
            "\n",
            "Contagem de valores ausentes por coluna:\n",
            "+----+-----+------+----+\n",
            "|nome|idade|altura|peso|\n",
            "+----+-----+------+----+\n",
            "|   0|    0|     0|   0|\n",
            "+----+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}